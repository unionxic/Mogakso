# 전체 흐름과 프로젝트 목적.
* RWF-2000이라는 폭력 감지 데이터셋을 활용해, 딥러닝 모델이 주어진 영상에서 폭력장면을 판단하는 시스템 제작.
* 접근방식
    1. 비디오 데이터를 받아 일정한 개수의 프레임 추출.
    2. 추출한 프레임들을 전처리(정규화, 리사이즈)하여 모델에 입력 가능하게.
    3. U-Net-like 구조의 MobileNetV2 인코더로부터 공간 특징을 추출
    4. LSTM을 통해 시간적 특징을 학습한 뒤 최종적으로 폭력 여부 판단.
* colab 환경에서 진행됐으며, RWF-2000/train 안의 Fight, NonFight 디렉토리에 데이터가 들어있다.
## 데이터 전처리 방식
1. 비디오 파일을 cv2.VideoCapture로 열기
2. 일정한 간격(step)으로 추출. (30fps)
3. 프레임 수가 부족할 경우 마지막 프레임을 반복하여 채움. -> 이 과정을 padding이라고 함.
4. 사이즈를 (224, 224)로 리사이즈.
5. RGB 형태로 통일.
6. numpy배열로 변환하여, (N, 30, 224, 224, 3)모양으로 데이터셋 형성. 이때 N은 전체 비디오 수.
    * 프레임을 추출하는 이유는 비디오를 직접 다루기에는 용량이 너무 크고, 모델 입력 형식이 한정적이기에 일정 구간마다 프레임을 뽑아서 고정된 시퀀스로 변환해야한다.
* 데이터 정규화의 필요성
    * 정규화(Normaliztion): 입력값을 일정 범위로 스케일링.
        * MobileNetV2는 [-1,1]을 선호.
        * 모델 학습시, 입력 범위가 너무 크거나 제각각이면, 학습 안정성이 떨어지고, 경사 하강 과정에서 불필요한 변동이 커짐.
        * tf.keras.applications.mobilenet_v2.preprocess_input을사용, 각 픽셀값을 적절히 조정하여 모델이 예측하기 좋은 범위로 스케일링

---

## 모델구조
* 이번 프로젝트에서는 U-Net-like + MobileNetV2 Encoder + LSTM 구조를 사용.
    1. U-Net-like
        * U-Net은 원래 이미지 분할(Segmentation)하기 위한 구조, 인코더와 디코더를 대칭적으로 배치해 중간에 스킵 커넥션을 붙여주는 형태.
        * 여기서는 U-Net을 전체적으로 사용하지 않고, 인코더 부분을 MobileNetV2를 사용. 디코더 부분은 LSTM으로 시계열 정보를 처리.
    2. MobileNetV2: 경량화된 CNN 아키텍처.
        * 특징
            * 파라미터 수가 적고, 연산량이 적어서 **임베디드/모바일 환경**에 적합.
            * 정확도 꽤 좋음.
        * 역할
            * 각 프레임에서 공간적(Spatial) 특징을 추출.
            * 즉, 프레임에 담긴 객체, 모션, 배경 등을 CNN으로 인코딩해 1280차원 특징 벡터로 압축.\
    3. LSTM(Long Short-Term Memory)
        * RNN의 한 종류, 시계열 정보를 잘 처리하도록 고안됨.
        * 특징
            * 장기 의존성(Long-term Dependency)을 학습할 수 있음.
            * 영상에서는 프레임 간의 흐름(시간적 변화를 학습)
            * MobileNetV2가 뽑은 30개의 특징 벡터를 순차적으로 입력받아, 폭력 여부를 결정하기 위한 시간적 패턴 파악.
    4. 왜 CNN + LSTM 조합일까??
        * 각각 공간 정보, 시간 정보 분석에 뛰어나다. 그래서 비디오는 2D 이미지가 시간축에 따라 변하는 3D 데이터이므로, 공간 + 시간 두가지 축을 모두 다뤄야하기에 저렇게 사용한 것.
    5. 활성화 함수(Activation Function)
        1. ReLu
            * 구현이 간단하고, 경사 소실 문제가 적다.
            * 뉴런이 음수가 되면 0으로 죽이고, 양수에서는 선형이므로 학습이 빠르다.
            * 은닉층(DNN의 중간 Dense레이어나 CNN 레이어 등)에 주로 사용.
        2. Sigmoid
            * 출력이 (0,1) 사이로 매핑되어 확률해석에 유리.
            * 다만, 큰 음수나 양수에서 기울기가 거의 0이라서 경사 소실 우려가 있음.
    6. 모델 학습 과정
        1. 손실 함수: **binary_crossentropy**
            * 이진 분류에서 사용. 예측값과 실제값 차이를 로그형태로 계산.
        2. 옵티마이저(optimizer): **Adam**
            * Adaptive Moment Estimation.
            * 학습률을 적절히 조절하면서 경사를 갱신해, 빠른 학습과 적절한 수렴을 만듦.
        3. 학습률 스케쥴: **ReduceLR0nPlateau**
            * 일정 에폭 이상 개선이 없으면 학습률을 줄여 세밀하게 학습하도록 유도.
        4. 정확도와 손실 곡선 해석
            * 학습 정확도가 급상승 -> 모델이 훈련 데이터에 맞춰서 잘 적응 중.
            * 검증 정확도(Val Accuracy)가 어떤 지점에서 정체 또는 하락한ㄴ다면 -> 오버피팅 가능성.
            * 학습손실(Train Loss)와 검증 손실(Val loss)가 모두 감소하는지 확인.
                * 검증 손실이 어느 순간부터 감소하지 않고 정체되거나 올라가면 학습률 조정 또는 정규화 방법 검토.
    7. 최종 모델 평가
        * 1열: TN FP, 2열: FN, TP 로 구성되어있는데.
        * TN: 실제 비폭력을 비폭력으로 잘 예측.
        * FP: 실제 비폭력인데, 폭력으로 잘못 예측.
        * FN: 실제 폭력인데 비폭력으로 잘못 예측.
        * TP: 실제 폭력인데 폭력으로 잘 예측.
        * Precision(정밀도): 모델이 폭력이라고 예측한 것 중 진짜 폭력이 몇 %인가
        * F1-score: 정밀도와 재현율의 조화평균 -> 종합적으로 성능이 어느 정도인지 파악하기 좋음.
    8. 로스율과 학습률 분석
        1. 로스율
            * 학습이 진행됨에 따라 트레이닝 손실(train loss)이 감소하는지,
            * 검증 손실(val loss)이 일정 지점에서 더 이상 안 줄어들고 정체되거나 다시 커지지 않는지 확인해야 함.
        2. 학습률
            * 초기에는 1e-4처럼 적당히 큰 값을 써서 빠르게 수렴,
            * 오버피팅이 일어나거나 더 세밀한 학습이 필요할 때는 ReduceR0nPlateau에 의해 1e-5, 1e-6처럼 낮아짐.
        3. 에폭(Epoch)
            * 한번의 에폭이란 전체 데이터를 한 바퀴 학습하는 것.
            * 에폭이 늘어날 수록, 정확도가 올라가지만, val accuracy가 정체되면 일반화 성능이 한꼐라는 것.
































